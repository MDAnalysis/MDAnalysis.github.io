---
layout: post
title: Introducing Distopia
---

Calculating Euclidian distances under periodic boundary conditions is a core component in both running and analysing molecular simulations. For example, the calculation of radial distribution functions, hydrogen bonds, structure factors, and many other common analyses require calculation of one or more pairwise Euclidian distances.

The Euclidian distance formula under periodic boundary conditions can be expressed as:

$$
R = \sqrt{A}
$$

Many molecular mechanics engines have highly optimised code for calculating distances that often make use of specialised code paths and/or accelerators to achieve maximal performance. However this functionality is often heavily "baked-in" and is not able to be used as a standalone component.

We at MDAnalysis wanted to bring some of this blazing speed to our distance calculations without sacrificing the modularity of MDAnalysis by introducing heavyweight dependencies on a simulation engine.

## Enter Distopia ##

Instead we developed a lightweight C++ / Python package **distopia** that uses explicit x86 SIMD vectorisation to accelerate calculation of Euclidian distances under periodic boundary conditions. The package is small and aims to provide both a Python and C++ layer to interface with if you would like to quickly calculate some distances! It is available on [PyPi][Distopia PyPi] and [conda forge][Distopia conda-forge] for x86 architectures if you would like to try it out. 

Try one of:

```bash
pip install distopia
```

or,

```bash
conda install -c conda-forge distopia
```

You can also see distopia under development at its home on  [github][Distopia github].

## What advantages does Distopia provide? ##

### Distopia is fast! ###

A comparison of distopia with several different approaches used in different simulation analysis packages is provided in the graph below. We compare with MDAnalysis's current distance backend, MDTraj's distance backend and freud's distance backend.


We can see that distopia is faster than the approaches taken in the other packages (especially MDAnalysis!). This is due to the extensive efforts taken to improve vectorisation, data alignment and use low-latency CPU operations. More details about how this is achieved can be found below.

### Distopia is easy to use! ###

Distopia is easy to use, with a simple, [well documented python layer][Distopia docs]. Calculating the pairwise distances between two NumPy arrays is as simple as.

 ```python
import distopia

dists = distopia.calc_bonds_ortho_float(coords1, coords2, box) 
 ```

Distopia provides both `float` and `double` precision versions of functions to calculate distances and currently supports orthorhombic periodic boundary conditions, or no boundary conditions.

### Distopia is open to the community! ###

We don't intend the benchmarks in this blog post to draw attention to relative performance of one package versus another. Instead we aim to discuss the merits of different approaches and provide an easy to use layer that other packages can adopt if they so wish.

We also welcome all kinds of feedback about distopia on our [github][Distopia github] or on the [MDAnalysis Discord][MDAnalysis discord].

## How does distopia compare to existing approaches? ##

Currently, many simulation analysis packages offer some kind of compiled layer for the numerically intensive job of calculating distances. MDAnalysis currently achieves this with a C header wrapped in Cython.

Distopia uses **explicit SIMD vectorisation** along with a set of "array of structs" -> "struct of arrays" transforms to get the maximum speed out of the available CPU hardware. 

Lets break down what each of these mean:

### SIMD vectorisation ###

Optimising compilers aim to use the best possible set of CPU instructions, data pipelines and branch predictions to run code as fast as possible. Part of this involves the automatic compilation of code to use  **Single Instruction Multiple Data** instructions that broadcast an operation over multiple data elements using specialised registers. For example, an AVX SIMD enabled **multiply** may be able to work on a 8 32 bit floats at a time using a x86 `YMM` register introduced with the AVX SIMD instruction set. 

The following C++ snippet compiled with `clang 15` using the `-O3` and `-mavx2` flags shows this nicely. It computes the scalar product  $c = a * b$

```c++
void sax(float *c, float *a, float *b, int n) {
    for (size_t i=0; i<n; i++) {
        c[i] = a[i] * b[i];
    }
}

```
Resulting in the following assembly with only the core of the unrolled loop
shown:

```assembly

.LBB0_6:                                # Only loop core shown
        vmovups ymm0, ymmword ptr [rsi + rax]
        vmovups ymm1, ymmword ptr [rsi + rax + 32]
        vmovups ymm2, ymmword ptr [rsi + rax + 64]
        vmovups ymm3, ymmword ptr [rsi + rax + 96]
        vmulps  ymm0, ymm0, ymmword ptr [rdx + rax]
        vmulps  ymm1, ymm1, ymmword ptr [rdx + rax + 32]
        vmulps  ymm2, ymm2, ymmword ptr [rdx + rax + 64]
        vmulps  ymm3, ymm3, ymmword ptr [rdx + rax + 96]
        vmovups ymmword ptr [rdi + rax], ymm0
        vmovups ymmword ptr [rdi + rax + 32], ymm1
        vmovups ymmword ptr [rdi + rax + 64], ymm2
        vmovups ymmword ptr [rdi + rax + 96], ymm3
```

However the compiler cannot see all ends and is often incapable of identifying large scale data transformations that may result in better SIMD utilisation down the line. The MDAnalysis distance library is a good example of this, showing limited used of the SIMD registers that would result in better performance when compiled with SIMD compiler flags.

So what can we do to remedy this situation? There are two main possible paths that vary in difficulty.

1. We can try and help the compiler by organising the data in a manner that might help it 

2. We can use **explicit vectorisation** where we use C++ functions that directly embed the assembly instructions we want (or very close to) in the generated assembly. This allows us to have much more control over when and how data is transformed into SIMD constructs.

Packages like Freud use option 1, while MDTraj and MDAnalysis use option 2 but in different ways. 

Lets explore each of these in slightly more depth:


#### Option 1: Helping the compiler ####

Our first strategy is to try and make the compilers job easier by laying out the data in a way that it can more readily identify opportunities for vectorisation.
The easiest way to show this is with an example. Consider the following code for computing distances taken from the `freud` simulation analysis package.

```c++

inline float computeDistance(vec3<float>& r_i, vec3<float>& r_j) {
    const vec3<float> r_ij = wrap(r_j - r_i);
    return std::sqrt(dot(r_ij, r_ij));
}

// where the vec3 datastructure is roughly

template<class Real> struct vec3
{
    Real x {0};
    Real y {0};
    Real z {0};
};

template<class Real> inline vec3<Real> operator*(const vec3<Real>& a, const vec3<Real>& b) {

    return vec3<Real>(a.x * b.x, a.y * b.y, a.z * b.z);
}

```

Using the `vec3` datastructure enables the compiler to **automatically** generate more optimally vectorised code, as the operations on the `x`, `y` and `z` elements of the vectors can be separated into registers as operations on coordinates are paired.

For example, `x` coordinates can easily be multiplied with `x` coordinates and `y` with `y` (in this case using operator overloading) resulting in more opportunities for vectorisation.


This is sometimes called a Struct Of Arrays (SOA) data layout rather than an Array of Structs (AOS) layout and is best demonstrated by comparing the two example classes. 

```c++

class SOA {
    // an array for each dimensions
    float* x; // xxxxx...
    float* y; // yyyyy...
    float* z; // zzzzz...
};

class AOS {
    // an array containing repeated coordinartes
    float* coordinates; //xyzxyzxyz.....
};
```

This approach is a fantastic first step for optimising compiler vectorisation.  However, we can do more.


#### Option 2: Explicit vectorisation ####

Rather than relying on the compiler to do our vectorisation for us, we can use **SIMD intrinsics** to have a much finer grained control over vectorisation in our program. The general way SIMD intrinsics work is that a single C++ intrinsic function roughly corresponds to a single CPU instruction but does not require writing of assembly. For example we could write our `sax()` function from  above using AVX2 intrinsics  as such:

```c++
#include <immintrin.h>

void sax(float *c, float *a, float *b, int n) {
    for (size_t i=0; i<n; i+=8) {
        __m256 a_ = _mm256_loadu_ps(a+i); // load 8 values into a 256 bit YMM register
        __m256 b_ = _mm256_loadu_ps(b+i); // load 8 values into a 256 bit YMM register
        __m256 c_ = _mm256_mul_ps(a_, b_); // multiply 2x YMM register
        _mm256_store_ps(c + i,  c_); // store the result
    }
}

```

This results in the very compact assembly (only core loop shown)


```assembly
.LBB0_2:                                # only core loop shown
        vmovups ymm0, ymmword ptr [rsi + 4*rcx]
        vmulps  ymm0, ymm0, ymmword ptr [rdx + 4*rcx]
        vmovaps ymmword ptr [rdi + 4*rcx], ymm0
        add     rcx, 8
        cmp     rcx, rax
        jb      .LBB0_2
```

While the loop in the pervious example is slightly more unrolled, the use of explicit vector instructions has streamlined the assembly and resulted in
a very tight and compact inner loop and the use of the `vmovaps` instruction


So how can we apply explicit vectorisation in our code for calculating distances?

One way is to use SIMD intrinsics to perform our calculation in **AOS** format.  This is the approach taken in the MDTraj library.




## So how does distopia work? ##

Distopia is  




[Distopia github]: https://github.com/MDAnalysis/distopia
[Distopia PyPi]: https://pypi.org/project/distopia/
[Distopia conda-forge]: https://github.com/conda-forge/distopia-feedstock
[Distopia docs]: https://www.mdanalysis.org/distopia
[MDAnalysis discord]: https://www.mdanalysis.org/2021/03/20/discord/